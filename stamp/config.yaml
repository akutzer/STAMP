# Main configuration file for STAMP.
# 
# NOTE: you may use environment variables in this file, e.g. ${oc.env:STAMP_RESOURCES_DIR}.
# The STAMP_RESOURCES_DIR environment variable is a special environment variable that, if not set, will be set to the resources/ directory relative to where STAMP is installed.

# Only use absolute paths!

preprocessing:
  output_dir: /mnt/bulk-io/maurice/LEOPARD_CHALLENGE/data/outputs_ctp_norm/features # Path to save features to
  wsi_dir: /mnt/bulk-io/maurice/LEOPARD_CHALLENGE/data/wsi # Path of where the whole-slide images are.
  cache_dir: /mnt/bulk-io/maurice/LEOPARD_CHALLENGE/data/outputs_ctp_norm/cache_dir # Directory to store intermediate slide JPGs
  microns: 256 # Edge length in microns for each patch (default is 256, with pixel size 224, 256/224 = ~1.14MPP = ~9x magnification)
  norm: true # Perform Macenko normalisation
  feat_extractor: ctp # Use ctp for CTransPath (default) or uni for UNI (requires prior authentication)
  del_slide: false # Remove the original slide after processing
  cache: true # Save intermediate images (slide, background rejected, normalized)
  only_feature_extraction: false # Only perform feature extraction (intermediate images (background rejected, [normalized]) have to exist)
  cores: 16 # CPU cores to use
  device: cuda # device to run feature extraction on (cpu, cuda, cuda:0, etc.)

modeling:
  clini_table: /mnt/bulk-io/lizhang/LiWorkSpace/leopard/data/tcga_leopard_clini_stamp.csv # Path to clini_table file (.xlsx or .csv)
  slide_table: /mnt/bulk-io/lizhang/LiWorkSpace/leopard/data/tcga_leopard_clini_stamp.csv # Path to slide_table file (.xlsx or .csv)
  feature_dir: /mnt/bulk-io/maurice/LEOPARD_CHALLENGE/data/tcga_leopard_ctp_norm # Path to feature directory
  output_dir: /mnt/bulk-io/lizhang/LiWorkSpace/leopard/experiemnts/crossval_tcga_leopard/bs16_bags512_cox_transform # Path to output directory
  target_label: ['follow_up_years', 'event'] # Target label. No spaces allowed! Format clinical table accordingly
  categories: [] # Categories (list), leave empty to automatically infer based on unique values in the target_label column
  cat_labels: [] # Extra input category labels (list, can be empty)
  cont_labels: [] # Extra input continuous labels (list, can be empty)
  n_splits: 5 # Number of splits for cross-validation (only applicable to cross-validation)
  model_path: /path/to/export.pkl # Path to saved model (only applicable to deployment)
  deploy_feature_dir: # Path to directory containing the external cohort features (only applicable to deployment)
  method: cox # "cox" or "logistic-hazard" 
  num_bins: 10  # number of intervals for logistic-hazard loss
  aggregation: trans_mil # selects the aggregation mechanism: trans_mil, attn_mil
  extra_data: True
  
  statistics:
    pred_csvs: # Paths to prediction CSVs to plot ROC curves for
      - /stamp/data/fold-0/patient-preds.csv # only need 1 path when fully training (remove second one)
      - /stamp/data/fold-1/patient-preds.csv # for cross-validation, you will have fold-0, fold-1, fold-k, add below
      - /stamp/data/fold-2/patient-preds.csv
      - /stamp/data/fold-3/patient-preds.csv
      - /stamp/data/fold-4/patient-preds.csv
    method: ${modeling.method}
    output_dir: /stamp/data # Path to save ROC curve and statistics to
  
heatmaps:
  slide_name: # Name of the slide to create heatmaps for, wildcards allowed, no file extensions
  feature_dir: ${preprocessing.output_dir} # Path to feature directory
  wsi_dir: # Path to whole-slide image directory.
  model_path: /path/to/export.pkl # Path to saved model (only applicable to deployment)
  output_dir: # Path to output directory
  n_toptiles: 8 # Number of toptiles, default is 8
  overview: true # Create final overview image